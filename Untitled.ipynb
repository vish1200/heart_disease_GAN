{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import time\n",
    "from IPython import display\n",
    "import math\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxNormalise(data, cont_ls):\n",
    "    for j in cont_ls:\n",
    "        index = list(data.index.values)\n",
    "        df_ = pd.DataFrame(index=index, columns=[j])\n",
    "        for i in index:\n",
    "            df_.at[i,j] = (data.at[i,j]-data[j].min())/(data[j].max()-data[j].min())\n",
    "        data.at[:,j] = np.nan\n",
    "        for k in index:\n",
    "            data.at[k,j] = df_.at[k,j]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEnc(data, cat_ls):\n",
    "    for i in cat_ls:\n",
    "        col_df = data[i]\n",
    "        encoded_df = pd.get_dummies(col_df, prefix = [i])\n",
    "        data = data.drop([i], axis=1)\n",
    "        data = pd.concat([data, encoded_df], axis = 1, sort=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(m, n):\n",
    "    seed = np.random.uniform(-1., 1., size=[m, n])\n",
    "    seed = np.sort(seed)\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61,)\n",
      "86.89\n",
      "(303, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('heart-disease-uci.zip')\n",
    "data_process = False\n",
    "if data_process:    \n",
    "    cont_ls = ['age', 'trestbps', 'chol', 'thalach','oldpeak']\n",
    "    data = minMaxNormalise(data, cont_ls)\n",
    "    cat_col = ['cp', 'slope', 'thal']\n",
    "    data = oneHotEnc(data, cat_col)\n",
    "\n",
    "gan_data = data\n",
    "target_df = data['target']\n",
    "variables = data.drop(['target'], axis=1)\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(variables, target_df, test_size=0.20, random_state=42)\n",
    "print(label_test.shape)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(data_train, label_train)\n",
    "accuracy = round(logreg.score(data_test, label_test)*100, 2)\n",
    "print(accuracy)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "0.051642751693725585\n",
      "Iterations: 0\t Discriminator loss: 1.2122\t Generator loss: 0.7239\n",
      "2.7114898840586346\n",
      "Iterations: 4000\t Discriminator loss: 0.8107\t Generator loss: 0.5467\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "tf.reset_default_graph()\n",
    "start = time.time()\n",
    "num_points = gan_data.shape[1]\n",
    "gen_input_size = 100\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "batch_size = 256\n",
    "epochs = 4001\n",
    "steps_per_epoch = 1\n",
    "def generator():\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(1000, input_dim=gen_input_size))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "#     generator.add(Dense(200))\n",
    "#     generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(num_points))\n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return generator\n",
    "\n",
    "def discriminator():\n",
    "    discriminator = Sequential()\n",
    "    \n",
    "    discriminator.add(Dense(1000, input_dim=num_points))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss = 'binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "discriminator = discriminator()\n",
    "generator = generator()\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = Input(shape=(gen_input_size,))\n",
    "generated_patient = generator(gan_input)\n",
    "gan_output = discriminator(generated_patient)\n",
    "\n",
    "gan = Model(gan_input, gan_output)\n",
    "\n",
    "gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for steps in range(steps_per_epoch):\n",
    "        noise = sample_z(batch_size, gen_input_size)\n",
    "        fake_x = generator.predict(noise)\n",
    "        real_x = gan_data.sample(n=batch_size)\n",
    "        x = np.concatenate((real_x, fake_x))\n",
    "        disc_y = np.zeros(2*batch_size)\n",
    "        disc_y[:batch_size] = 0.9\n",
    "        d_loss = discriminator.train_on_batch(x, disc_y)\n",
    "        y_gen = np.ones(batch_size)\n",
    "        g_loss = gan.train_on_batch(noise, y_gen)\n",
    "        \n",
    "    if epoch%4000 == 0:\n",
    "        print((time.time()-start)/60)\n",
    "        print(\"Iterations: %d\\t Discriminator loss: %.4f\\t Generator loss: %.4f\"%(epoch,d_loss,g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.5078789e+01  1.7386907e+00  3.4228804e+00  1.4059810e+02\n",
      "   3.0308554e+02 -2.5302953e-01  1.2681668e+00  1.2660324e+02\n",
      "   2.0212717e+00  2.7716613e+00  3.2260137e+00 -5.7258421e-01\n",
      "   7.0259923e-01  7.1009207e-01]]\n",
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "202   58    1   0       150   270    0        0      111      1      0.8   \n",
      "\n",
      "     slope  ca  thal  target  \n",
      "202      2   0     3       0  \n"
     ]
    }
   ],
   "source": [
    "a = generator.predict(sample_z(1, gen_input_size))\n",
    "print(a)\n",
    "print(gan_data.sample(n=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
